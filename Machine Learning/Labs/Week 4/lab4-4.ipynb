{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9515776d",
   "metadata": {},
   "source": [
    "# COMP809 - Lab 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00322c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm;\n",
    "import scipy;\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a46bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"framingham.csv\");\n",
    "df = df.dropna(); # eliminate NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958d6c3",
   "metadata": {},
   "source": [
    "## Question 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e10004f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TenYearCHD\n",
      "0    3099\n",
      "1     557\n",
      "Name: TenYearCHD, dtype: int64\n",
      "Percentage of 0s: 84.76477024070022\n",
      "Percentage of 1s: 15.23522975929978\n"
     ]
    }
   ],
   "source": [
    "# Yes, the data is unbalanced.  We have 85% of 0s and 15% of 1s.\n",
    "\n",
    "response_count = df.groupby(\"TenYearCHD\")[\"TenYearCHD\"].count();\n",
    "print(response_count);\n",
    "print(\"Percentage of 0s:\", 100*response_count[0]/np.sum(response_count));\n",
    "print(\"Percentage of 1s:\", 100*response_count[1]/np.sum(response_count));\n",
    "\n",
    "df.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c226e",
   "metadata": {},
   "source": [
    "### Question 1 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a1c82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that if we train the model with this data set, the model could just predict any response \n",
    "# as a 0, for any predictor values, having an approximated accuracy 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f693b",
   "metadata": {},
   "source": [
    "### Question 1 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29220bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the techniques to deal with unbalanced data is oversampling.\n",
    "# This method works as follows: those observations with a response value that is minority are \n",
    "# sampled with replacement M times, where M is the number of observations with a response value \n",
    "# that is majority.\n",
    "\n",
    "# Thus, failures and successes are equated\n",
    "\n",
    "# We could also apply downsampling, in which case observations from the majority group are \n",
    "# randomly removed to equate this category to the minority group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e6cf8",
   "metadata": {},
   "source": [
    "## Question 1 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "158a5c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TenYearCHD\n",
      "0    3099\n",
      "1    3099\n",
      "Name: TenYearCHD, dtype: int64\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             TenYearCHD   No. Observations:                 6198\n",
      "Model:                            GLM   Df Residuals:                     6182\n",
      "Model Family:                Binomial   Df Model:                           15\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -3722.0\n",
      "Date:                Thu, 04 Apr 2024   Deviance:                       7444.1\n",
      "Time:                        16:33:03   Pearson chi2:                 6.17e+03\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):             0.1691\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -6.5345      0.405    -16.119      0.000      -7.329      -5.740\n",
      "C(male)[T.1]                0.5247      0.062      8.524      0.000       0.404       0.645\n",
      "C(currentSmoker)[T.1]       0.0564      0.093      0.605      0.545      -0.126       0.239\n",
      "C(BPMeds)[T.1.0]           -0.0061      0.159     -0.039      0.969      -0.318       0.306\n",
      "C(prevalentStroke)[T.1]     0.6933      0.341      2.036      0.042       0.026       1.361\n",
      "C(prevalentHyp)[T.1]        0.3200      0.081      3.954      0.000       0.161       0.479\n",
      "C(diabetes)[T.1]            0.1975      0.207      0.953      0.341      -0.209       0.604\n",
      "age                         0.0644      0.004     16.707      0.000       0.057       0.072\n",
      "education                  -0.0605      0.028     -2.193      0.028      -0.114      -0.006\n",
      "cigsPerDay                  0.0203      0.004      5.281      0.000       0.013       0.028\n",
      "totChol                     0.0018      0.001      2.877      0.004       0.001       0.003\n",
      "sysBP                       0.0147      0.002      6.445      0.000       0.010       0.019\n",
      "diaBP                      -0.0086      0.004     -2.298      0.022      -0.016      -0.001\n",
      "BMI                         0.0192      0.007      2.639      0.008       0.005       0.033\n",
      "heartRate                   0.0006      0.002      0.268      0.788      -0.004       0.005\n",
      "glucose                     0.0051      0.001      3.615      0.000       0.002       0.008\n",
      "===========================================================================================\n",
      "8592.252450221082\n",
      "7444.072190827779\n",
      "Pearson chi2 p-value: 0.5351802600275923\n",
      "Deviance p-value: 1.0\n",
      "Null deviance: 8592.252450221082\n",
      "Residual deviance: 7444.072190827779\n",
      "Degrees of freedom for null model: 14\n",
      "Degrees of freedom for residual model: 6182\n",
      "Chi-square value: 1148.1802593933025\n",
      "p-value: 1.0\n",
      "#####\n",
      "Residual Deviance: 7444.072190827779\n",
      "Residual Degrees of Freedom: 6182\n",
      "Chi-squared Statistic: 1.2041527322594272\n",
      "p-value: 1.0\n",
      "Pearson2 / Df 0.9983049087888635\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             TenYearCHD   No. Observations:                 6198\n",
      "Model:                            GLM   Df Residuals:                     6182\n",
      "Model Family:                Binomial   Df Model:                           15\n",
      "Link Function:                  Logit   Scale:                         0.99830\n",
      "Method:                          IRLS   Log-Likelihood:                -3722.0\n",
      "Date:                Thu, 04 Apr 2024   Deviance:                       7444.1\n",
      "Time:                        16:33:03   Pearson chi2:                 6.17e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.1691\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -6.5345      0.405    -16.133      0.000      -7.328      -5.741\n",
      "C(male)[T.1]                0.5247      0.062      8.531      0.000       0.404       0.645\n",
      "C(currentSmoker)[T.1]       0.0564      0.093      0.606      0.545      -0.126       0.239\n",
      "C(BPMeds)[T.1.0]           -0.0061      0.159     -0.039      0.969      -0.318       0.306\n",
      "C(prevalentStroke)[T.1]     0.6933      0.340      2.038      0.042       0.026       1.360\n",
      "C(prevalentHyp)[T.1]        0.3200      0.081      3.957      0.000       0.162       0.478\n",
      "C(diabetes)[T.1]            0.1975      0.207      0.954      0.340      -0.208       0.603\n",
      "age                         0.0644      0.004     16.721      0.000       0.057       0.072\n",
      "education                  -0.0605      0.028     -2.195      0.028      -0.114      -0.006\n",
      "cigsPerDay                  0.0203      0.004      5.285      0.000       0.013       0.028\n",
      "totChol                     0.0018      0.001      2.879      0.004       0.001       0.003\n",
      "sysBP                       0.0147      0.002      6.450      0.000       0.010       0.019\n",
      "diaBP                      -0.0086      0.004     -2.300      0.021      -0.016      -0.001\n",
      "BMI                         0.0192      0.007      2.641      0.008       0.005       0.033\n",
      "heartRate                   0.0006      0.002      0.269      0.788      -0.004       0.005\n",
      "glucose                     0.0051      0.001      3.618      0.000       0.002       0.008\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Oversampling \n",
    "df_minority = df[(df['TenYearCHD']==1)]; \n",
    "df_majority = df[(df['TenYearCHD']==0)];  \n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples= response_count[0], # to match majority class\n",
    "                                 random_state=123);  # reproducible results\n",
    "df_minority_upsampled.reset_index(drop=True, inplace=True); # reseting row numbers\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_minority_upsampled, df_majority]);\n",
    "response_count = df_upsampled.groupby(\"TenYearCHD\")[\"TenYearCHD\"].count();\n",
    "print(response_count);\n",
    "\n",
    "# Undersampling -- in case you want to use this option\n",
    "# downsample majority class\n",
    "#df_majority_downsampled = resample(df_majority, \n",
    "#                                 replace=False,    # sample with replacement\n",
    "#                                 n_samples= response_count[1], # to match minority class\n",
    "#                                 random_state=123);  # reproducible results\n",
    "\n",
    "#print(df_minority_upsampled)\n",
    "#list(df_minority_upsampled.columns)\n",
    "\n",
    "model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n",
    "                             cigsPerDay + C(BPMeds) + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n",
    "                             totChol + sysBP + diaBP + BMI + heartRate+ glucose\", family = sm.families.Binomial(), \n",
    "                             data=df_upsampled);\n",
    "result = model.fit();\n",
    "print(result.summary());\n",
    "\n",
    "# The null deviance shows how well the response is predicted by the model with nothing but an intercept\n",
    "print(result.null_deviance); \n",
    "# The residual deviance shows how well the response is predicted by the model when the predictors are included.\n",
    "print(result.deviance);\n",
    "\n",
    "# Since there are many continuous predictors, it is highly likely that the responses are ungrouped,\n",
    "# in which case the overdispersion cannot occur.\n",
    "# But we will check it anyway.\n",
    "\n",
    "dev = result.deviance; # Residual Deviance\n",
    "dof = result.df_resid; # Degree of freedoms of Residuals (n-p)\n",
    "#n   = result.nobs;   ; # Number of observations\n",
    "\n",
    "# To see the elements on result, visit\n",
    "#https://www.statsmodels.org/dev/generated/statsmodels.genmod.generalized_linear_model.GLMResults.html\n",
    "\n",
    "# H0: Logistic regression model provides an adequate fit for the data\n",
    "# H1: Logistic regression model does not provide an adequate fit for the data\n",
    "\n",
    "print(\"Pearson chi2 p-value:\", 1 - scipy.stats.chi2.cdf(result.pearson_chi2, dof))\n",
    "print(\"Deviance p-value:\", 1 - scipy.stats.chi2.cdf(dev/dof, dof))\n",
    "\n",
    "# Pearson chi2 test does not support H1\n",
    "# However, Deviance test does support H1, which is in contradiction with Pearson chi2 test\n",
    "# Since the data is not grouped, this should not be a problem.\n",
    "\n",
    "##############\n",
    "from scipy.stats import chi2\n",
    "null_deviance = result.null_deviance\n",
    "residual_deviance = result.deviance\n",
    "df_null = result.df_model - 1\n",
    "df_residual = result.df_resid\n",
    "chi2 = null_deviance - residual_deviance\n",
    "p_value = 1 - scipy.stats.chi2.cdf(chi2, df_residual - df_null)\n",
    "\n",
    "print(\"Null deviance:\", null_deviance)\n",
    "print(\"Residual deviance:\", residual_deviance)\n",
    "print(\"Degrees of freedom for null model:\", df_null)\n",
    "print(\"Degrees of freedom for residual model:\", df_residual)\n",
    "print(\"Chi-square value:\", chi2)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "###################################\n",
    "print(\"#####\")\n",
    "residual_deviance = result.deviance\n",
    "null_deviance = result.null_deviance\n",
    "\n",
    "# Calculate residual degrees of freedom\n",
    "residual_df = result.df_resid\n",
    "# Compare residual deviance to residual degrees of freedom\n",
    "chi2_statistic = residual_deviance / residual_df\n",
    "p_value = 1 - scipy.stats.chi2.cdf(chi2_statistic, residual_df)\n",
    "\n",
    "print(\"Residual Deviance:\", residual_deviance)\n",
    "print(\"Residual Degrees of Freedom:\", residual_df)\n",
    "print(\"Chi-squared Statistic:\", chi2_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "#############\n",
    "\n",
    "# Rules of thumb   \n",
    "    \n",
    "# Calculation of Pearson chi2 / n - (p+1)\n",
    "print(\"Pearson2 / Df\",result.pearson_chi2 / result.df_resid);\n",
    "# This value is close to 1\n",
    "\n",
    "# We also fit a quasi-binomial model\n",
    "result2 = model.fit(scale=\"X2\");\n",
    "print(result2.summary());\n",
    "\n",
    "# The scale parameter is close to 1 in this model\n",
    "\n",
    "# Conclusion: the logistic regression model provides an adequate fit for the data, \n",
    "# even though this hypothesis was rejected according to the chi-square test.\n",
    "\n",
    "# See chaper 13 of Introduction to linear regression analysis \n",
    "# by Montgomery, Douglas C., author.; Peck, Elizabeth A., author.; Vining, G. Geoffrey, author.\n",
    "# to know about model selection criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33f24610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             TenYearCHD   No. Observations:                 6198\n",
      "Model:                            GLM   Df Residuals:                     6186\n",
      "Model Family:                Binomial   Df Model:                           11\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -3722.7\n",
      "Date:                Thu, 04 Apr 2024   Deviance:                       7445.4\n",
      "Time:                        16:33:03   Pearson chi2:                 6.17e+03\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):             0.1689\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -6.5088      0.361    -18.007      0.000      -7.217      -5.800\n",
      "C(male)[T.1]                0.5239      0.061      8.616      0.000       0.405       0.643\n",
      "C(prevalentStroke)[T.1]     0.6925      0.340      2.037      0.042       0.026       1.359\n",
      "C(prevalentHyp)[T.1]        0.3231      0.080      4.031      0.000       0.166       0.480\n",
      "age                         0.0642      0.004     16.787      0.000       0.057       0.072\n",
      "education                  -0.0623      0.027     -2.266      0.023      -0.116      -0.008\n",
      "cigsPerDay                  0.0221      0.003      8.797      0.000       0.017       0.027\n",
      "totChol                     0.0019      0.001      2.924      0.003       0.001       0.003\n",
      "sysBP                       0.0146      0.002      6.427      0.000       0.010       0.019\n",
      "diaBP                      -0.0086      0.004     -2.305      0.021      -0.016      -0.001\n",
      "BMI                         0.0189      0.007      2.615      0.009       0.005       0.033\n",
      "glucose                     0.0060      0.001      5.486      0.000       0.004       0.008\n",
      "===========================================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             TenYearCHD   No. Observations:                 6198\n",
      "Model:                            GLM   Df Residuals:                     6186\n",
      "Model Family:                Binomial   Df Model:                           11\n",
      "Link Function:                  Logit   Scale:                         0.99749\n",
      "Method:                          IRLS   Log-Likelihood:                -3722.7\n",
      "Date:                Thu, 04 Apr 2024   Deviance:                       7445.4\n",
      "Time:                        16:33:03   Pearson chi2:                 6.17e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.1689\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -6.5088      0.361    -18.029      0.000      -7.216      -5.801\n",
      "C(male)[T.1]                0.5239      0.061      8.627      0.000       0.405       0.643\n",
      "C(prevalentStroke)[T.1]     0.6925      0.339      2.040      0.041       0.027       1.358\n",
      "C(prevalentHyp)[T.1]        0.3231      0.080      4.036      0.000       0.166       0.480\n",
      "age                         0.0642      0.004     16.808      0.000       0.057       0.072\n",
      "education                  -0.0623      0.027     -2.269      0.023      -0.116      -0.008\n",
      "cigsPerDay                  0.0221      0.003      8.808      0.000       0.017       0.027\n",
      "totChol                     0.0019      0.001      2.928      0.003       0.001       0.003\n",
      "sysBP                       0.0146      0.002      6.435      0.000       0.010       0.019\n",
      "diaBP                      -0.0086      0.004     -2.308      0.021      -0.016      -0.001\n",
      "BMI                         0.0189      0.007      2.618      0.009       0.005       0.033\n",
      "glucose                     0.0060      0.001      5.493      0.000       0.004       0.008\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n",
    "                             cigsPerDay + C(BPMeds) + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n",
    "                             totChol + sysBP + diaBP + BMI + heartRate+ glucose\", family = sm.families.Binomial(), \n",
    "                             data=df_upsampled);\n",
    "\n",
    "# Deleting BPMeds since it has the highest p-value\n",
    "model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n",
    "                             cigsPerDay + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n",
    "                             totChol + sysBP + diaBP + BMI + heartRate+ glucose\", family = sm.families.Binomial(), \n",
    "                             data=df_upsampled);\n",
    "\n",
    "# Deleting heartRate since it has the highest p-value\n",
    "model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n",
    "                             cigsPerDay + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n",
    "                             totChol + sysBP + diaBP + BMI + glucose\", family = sm.families.Binomial(), \n",
    "                             data=df_upsampled);\n",
    "\n",
    "# Deleting C(currentSmoker) since it has the highest p-value\n",
    "model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + \\\n",
    "                             cigsPerDay + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n",
    "                             totChol + sysBP + diaBP + BMI + glucose\", family = sm.families.Binomial(), \n",
    "                             data=df_upsampled);\n",
    "\n",
    "# Deleting diabetes since it has the highest p-value\n",
    "model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + \\\n",
    "                             cigsPerDay + C(prevalentStroke) + C(prevalentHyp) +  \\\n",
    "                             totChol + sysBP + diaBP + BMI + glucose\", family = sm.families.Binomial(), \n",
    "                             data=df_upsampled);\n",
    "\n",
    "result = model.fit();\n",
    "print(result.summary());\n",
    "\n",
    "# Just to check the adequacy of the model\n",
    "result2 = model.fit(scale=\"X2\");\n",
    "print(result2.summary());\n",
    "# Note that the scale parameter is close to 1, so the logistic regression model provides an adequate fit for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a385a4",
   "metadata": {},
   "source": [
    "## Question 1 (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8294dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we increase in one unit the glucose level, the log odds of 10 year risk of coronary heart disease is expected to increase in 0.006 , holding the other predictors constant.\n",
      "If we increase in one unit the glucose level, the odds of 10 year risk of coronary heart disease is expected to increase in  1.006 , holding the other predictors constant.\n"
     ]
    }
   ],
   "source": [
    "print('If we increase in one unit the glucose level, the log odds of 10 year risk of coronary heart disease is expected to increase in',\\\n",
    "      round(result.params[\"glucose\"],3), \", holding the other predictors constant.\")\n",
    "\n",
    "print('If we increase in one unit the glucose level, the odds of 10 year risk of coronary heart disease is expected to increase in ',\\\n",
    "      round( np.exp(result.params[\"glucose\"]),3), \", holding the other predictors constant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e32822",
   "metadata": {},
   "source": [
    "## Question 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e0f2fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             TenYearCHD   No. Observations:                 4338\n",
      "Model:                            GLM   Df Residuals:                     4322\n",
      "Model Family:                Binomial   Df Model:                           15\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2624.8\n",
      "Date:                Thu, 04 Apr 2024   Deviance:                       5249.6\n",
      "Time:                        16:33:03   Pearson chi2:                 4.31e+03\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):             0.1615\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -6.2139      0.478    -13.002      0.000      -7.151      -5.277\n",
      "C(male)[T.1]                0.4636      0.073      6.340      0.000       0.320       0.607\n",
      "C(currentSmoker)[T.1]       0.0303      0.112      0.271      0.787      -0.189       0.249\n",
      "C(BPMeds)[T.1.0]            0.1392      0.186      0.750      0.453      -0.225       0.503\n",
      "C(prevalentStroke)[T.1]     0.5623      0.405      1.387      0.165      -0.232       1.357\n",
      "C(prevalentHyp)[T.1]        0.3473      0.096      3.601      0.000       0.158       0.536\n",
      "C(diabetes)[T.1]            0.0698      0.241      0.289      0.772      -0.403       0.542\n",
      "age                         0.0642      0.005     14.007      0.000       0.055       0.073\n",
      "education                  -0.0460      0.033     -1.404      0.160      -0.110       0.018\n",
      "cigsPerDay                  0.0207      0.005      4.504      0.000       0.012       0.030\n",
      "totChol                     0.0021      0.001      2.780      0.005       0.001       0.004\n",
      "sysBP                       0.0129      0.003      4.804      0.000       0.008       0.018\n",
      "diaBP                      -0.0104      0.004     -2.341      0.019      -0.019      -0.002\n",
      "BMI                         0.0191      0.009      2.217      0.027       0.002       0.036\n",
      "heartRate                   0.0007      0.003      0.240      0.810      -0.005       0.006\n",
      "glucose                     0.0053      0.002      3.146      0.002       0.002       0.009\n",
      "===========================================================================================\n",
      "Pearson chi2 p-value: 0.5569380559724502\n",
      "Deviance p-value: 0.0\n",
      "Pearson2 / Df 0.9967685069047872\n",
      "Confusion matrix:  \n",
      " [[642 274]\n",
      " [305 639]]\n",
      "Accuracy:  0.689\n",
      "Sensitivity:  0.677\n",
      "Specificity:  0.701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.678     0.701     0.689       916\n",
      "           1      0.700     0.677     0.688       944\n",
      "\n",
      "    accuracy                          0.689      1860\n",
      "   macro avg      0.689     0.689     0.689      1860\n",
      "weighted avg      0.689     0.689     0.689      1860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_upsampled.iloc[:, :-1];\n",
    "y = df_upsampled['TenYearCHD'];\n",
    "\n",
    "# Here we define training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,shuffle=True);\n",
    "\n",
    "aux = pd.concat([X_train, y_train], axis = 1);\n",
    "\n",
    "model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n",
    "                             cigsPerDay + C(BPMeds) + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n",
    "                             totChol + sysBP + diaBP + BMI + heartRate+ glucose\", family = sm.families.Binomial(), \n",
    "                             data=aux);\n",
    "result = model.fit();\n",
    "print(result.summary());\n",
    "\n",
    "### Checking Overdispersion ###\n",
    "\n",
    "# Since there are many continuous predictors, it is highly likely that the responses are ungrouped,\n",
    "# in which case the overdispersion cannot occur.\n",
    "# But we will check it anyway.\n",
    "\n",
    "dev = result.deviance; # Residual Deviance\n",
    "dof = result.df_resid; # Degree of freedoms of Residuals (n-p)\n",
    "#n   = result.nobs;   ; # Number of observations\n",
    "\n",
    "# To see the elements on result, visit\n",
    "#https://www.statsmodels.org/dev/generated/statsmodels.genmod.generalized_linear_model.GLMResults.html\n",
    "\n",
    "# H0: Logistic regression model provides an adequate fit for the data\n",
    "# H1: Logistic regression model does not provide an adequate fit for the data\n",
    "\n",
    "print(\"Pearson chi2 p-value:\", 1 - scipy.stats.chi2.cdf(result.pearson_chi2, dof))\n",
    "print(\"Deviance p-value:\", 1 - scipy.stats.chi2.cdf(dev, dof))\n",
    "\n",
    "# Pearson chi2 test does not support H1\n",
    "# However, Deviance test does support H1, which is in contradiction with Pearson chi2 test\n",
    "# Since the data is not grouped, this should not be a problem.\n",
    "\n",
    "# Rules of thumb   \n",
    "    \n",
    "# Calculation of Pearson chi2 / n - (p+1)\n",
    "print(\"Pearson2 / Df\", result.pearson_chi2 / result.df_resid);\n",
    "# This value is close to 1.  So the model provides an adequate fit for the data\n",
    "\n",
    "### Predictions ###\n",
    "predictions = result.predict(X_test);\n",
    "predictions_nominal = [ 0 if x < 0.5 else 1 for x in predictions];\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test, predictions_nominal)\n",
    "print(\"Confusion matrix: \", \"\\n\" , cm);\n",
    "# The diagonal elements of the confusion matrix indicate correct predictions,\n",
    "#  while the off-diagonals represent incorrect predictions\n",
    "\n",
    "# The logistic regression correctly predicted the 10 year risk of coronary heart disease 68.87% of the times\n",
    "print(\"Accuracy: \", round(np.sum(np.diagonal(cm))/np.sum(cm),3));\n",
    "\n",
    "# The model correctly predicted 67.7% of the times those with a 10 year risk of coronary heart disease\n",
    "print(\"Sensitivity: \", round(cm[1,1]/np.sum(cm[1,:]),3));\n",
    "\n",
    "# The model correctly predicted 70.7% of the times those without a 10 year risk of coronary heart disease\n",
    "print(\"Specificity: \", round(cm[0,0]/np.sum(cm[0,:]),3));\n",
    "\n",
    "# We can also get those values as follows\n",
    "print(classification_report(y_test, \n",
    "                            predictions_nominal, \n",
    "                            digits = 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40ebcb",
   "metadata": {},
   "source": [
    "## Question 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85a23c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative variability explained by PCs: \n",
      " [0.27 0.4  0.52 0.63 0.73 0.82 0.91 0.98 1.  ]\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             TenYearCHD   No. Observations:                 4338\n",
      "Model:                            GLM   Df Residuals:                     4328\n",
      "Model Family:                Binomial   Df Model:                            9\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2628.9\n",
      "Date:                Thu, 04 Apr 2024   Deviance:                       5257.7\n",
      "Time:                        16:33:04   Pearson chi2:                 4.31e+03\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):             0.1599\n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -0.3854      0.062     -6.173      0.000      -0.508      -0.263\n",
      "C(male)[T.1]             0.4580      0.072      6.345      0.000       0.317       0.599\n",
      "C(prevalentHyp)[T.1]     0.3772      0.094      3.999      0.000       0.192       0.562\n",
      "PC1                      0.3745      0.032     11.807      0.000       0.312       0.437\n",
      "PC2                     -0.0781      0.031     -2.500      0.012      -0.139      -0.017\n",
      "PC4                      0.3061      0.038      8.095      0.000       0.232       0.380\n",
      "PC5                     -0.1428      0.039     -3.645      0.000      -0.220      -0.066\n",
      "PC6                      0.3625      0.040      9.003      0.000       0.284       0.441\n",
      "PC8                     -0.3585      0.044     -8.157      0.000      -0.445      -0.272\n",
      "PC9                      0.2010      0.081      2.468      0.014       0.041       0.361\n",
      "========================================================================================\n",
      "Confusion matrix:  [[628 288]\n",
      " [308 636]]\n",
      "Acuraccy:  0.68\n",
      "Sensitivity:  0.677\n",
      "Specificity:  0.701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.671     0.686     0.678       916\n",
      "           1      0.688     0.674     0.681       944\n",
      "\n",
      "    accuracy                          0.680      1860\n",
      "   macro avg      0.680     0.680     0.680      1860\n",
      "weighted avg      0.680     0.680     0.680      1860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If multicollinearity is a problem, we can always transform the variables via PCA\n",
    "# and then fit the logistic regression model.\n",
    "\n",
    "# removing categorical nominal variables\n",
    "Xc_train  = X_train.drop([\"male\",\"currentSmoker\", \"BPMeds\", \"prevalentStroke\",\"prevalentHyp\",\"diabetes\"], axis = 1); \n",
    "\n",
    "scaler       = StandardScaler();     # Creating object\n",
    "fitted       = scaler.fit(Xc_train); # Calculating means and SDs\n",
    "Xc_train_std = fitted.transform(Xc_train); # Standardising data\n",
    "\n",
    "pca        = PCA(n_components=Xc_train_std.shape[1]); # Specifying number of PCs\n",
    "pca_fitted = pca.fit(Xc_train_std);                   # Calculating PC transformation\n",
    "PCAs       = pca_fitted.transform(Xc_train_std);      # Generating PCs\n",
    "print(\"Cumulative variability explained by PCs: \\n\", np.round(np.cumsum(pca.explained_variance_ratio_), 2))\n",
    "\n",
    "PCs = pd.DataFrame(data = PCAs,\n",
    "                   columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\"])\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True) # removing row names\n",
    "y_train.reset_index(drop=True, inplace=True) # removing row names\n",
    "\n",
    "DF = pd.concat([y_train, X_train[[\"male\",\"currentSmoker\", \"BPMeds\",\"prevalentStroke\",\"prevalentHyp\",\"diabetes\"]], PCs], axis = 1);\n",
    "\n",
    "# We fit a linear model with all the principal components and perform back selection \n",
    "# using a significance level of 0.05\n",
    "\n",
    "# Model with all the principal components\n",
    "#model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(currentSmoker) + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) +\\\n",
    "#                             PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9\", family = sm.families.Binomial(), \n",
    "#                             data=DF);\n",
    "\n",
    "# Removing currentSmoker\n",
    "#model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) +\\\n",
    "#                             PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9\", family = sm.families.Binomial(), \n",
    "#                             data=DF);\n",
    "\n",
    "# Removing diabetes\n",
    "#model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(prevalentStroke) + C(prevalentHyp) +\\\n",
    "#                             PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9\", family = sm.families.Binomial(), \n",
    "#                             data=DF);\n",
    "\n",
    "# Removing PC7\n",
    "#model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(prevalentStroke) + C(prevalentHyp) +\\\n",
    "#                             PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC8 + PC9\", family = sm.families.Binomial(), \n",
    "#                             data=DF);\n",
    "\n",
    "# Removing prevalentStroke\n",
    "#model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(prevalentHyp) +\\\n",
    "#                             PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC8 + PC9\", family = sm.families.Binomial(), \n",
    "#                             data=DF);\n",
    "\n",
    "# Removing PC3\n",
    "model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(prevalentHyp) +\\\n",
    "                             PC1 + PC2 + PC4 + PC5 + PC6 + PC8 + PC9\", family = sm.families.Binomial(), \n",
    "                             data=DF);\n",
    "\n",
    "result_pca = model_pca.fit();\n",
    "print(result_pca.summary());\n",
    "\n",
    "Xc_test = X_test.drop([\"male\",\"currentSmoker\",\"BPMeds\", \"prevalentStroke\",\"prevalentHyp\",\"diabetes\"], axis = 1); # continuous variables\n",
    "Xc_test_std = fitted.transform(Xc_test); # standardised data\n",
    "\n",
    "X_pca_test = pca_fitted.transform(Xc_test_std);\n",
    "X_pca_test = pd.DataFrame(data = X_pca_test,\n",
    "                   columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\"])\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True) # removing row names\n",
    "y_test.reset_index(drop=True, inplace=True) # removing row names\n",
    "X_pca_test = pd.concat([y_test, X_test[[\"male\",\"currentSmoker\", \"BPMeds\",\"prevalentStroke\",\"prevalentHyp\",\"diabetes\"]], X_pca_test], axis = 1);\n",
    "\n",
    "predictions_pca = result_pca.predict(X_pca_test);\n",
    "predictions_pca_nominal = [ 0 if x < 0.5 else 1 for x in predictions_pca];\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm_pca = confusion_matrix(y_test, predictions_pca_nominal)\n",
    "print(\"Confusion matrix: \", cm_pca);\n",
    "# The diagonal elements of the confusion matrix indicate correct predictions,\n",
    "#  while the off-diagonals represent incorrect predictions\n",
    "\n",
    "# The logistic regression correctly predicted the 10 year risk of coronary heart disease 68% of the times\n",
    "print(\"Acuraccy: \", round(np.sum(np.diagonal(cm_pca))/np.sum(cm_pca),3));\n",
    "\n",
    "# The model correctly predicted 67.7% of the times those with a 10 year risk of coronary heart disease\n",
    "print(\"Sensitivity: \", round(cm[1,1]/np.sum(cm_pca[1,:]),3));\n",
    "\n",
    "# The model correctly predicted 70.1% of the times those without a 10 year risk of coronary heart disease\n",
    "print(\"Specificity: \", round(cm[0,0]/np.sum(cm_pca[0,:]),3));\n",
    "\n",
    "# We can also get those values as follows\n",
    "print(classification_report(y_test, \n",
    "                            predictions_pca_nominal, \n",
    "                            digits = 3))\n",
    "\n",
    "# The results are similar to the ones obtain when using the original predictors.\n",
    "# However, the PC predictors are not correlated.\n",
    "\n",
    "# PC7 is not statistically significant, therefore, it could be removed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1a5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95578963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
